{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "214522c3-a8bd-459f-9d11-4b32eebaa83e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in /home/yassinb/.local/lib/python3.10/site-packages (3.2.1)\n",
      "Requirement already satisfied: py4j==0.10.9.3 in /home/yassinb/.local/lib/python3.10/site-packages (from pyspark) (0.10.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8230a4-9a92-41dd-b300-a865085effa7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63ea21f0-66a0-4213-b44e-2cf1041dff18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark_application_name = \"Spark_Application_Name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267a5bda-8b11-44d9-97b9-878ab55bc4b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/13 11:45:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/06/13 11:45:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/06/13 11:45:24 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder.appName(spark_application_name).getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8be55407-8ae5-47a9-b3c3-1844db3fb0b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filePath = \"sf-stocks-clean.parquet\"\n",
    "stocksDF = spark.read.parquet(filePath)\n",
    "(trainDF, testDF) = stocksDF.randomSplit([.8, .2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "603c8e64-3cf0-43d0-8f0b-d18ce41260d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "categoricalCols = []\n",
    "for (field, dataType) in trainDF.dtypes:\n",
    "    if dataType == \"string\":\n",
    "        categoricalCols.append(field)\n",
    "\n",
    "indexOutputCols = [x + \"Index\" for x in categoricalCols]\n",
    "\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=indexOutputCols, handleInvalid=\"skip\")\n",
    "\n",
    "numericCols = []\n",
    "for (field, dataType) in trainDF.dtypes:\n",
    "    if dataType == \"double\" and field != \"Low\":\n",
    "        numericCols.append(field)\n",
    "\n",
    "assemblerInputs = indexOutputCols + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b07dd5a-56d1-49cd-8263-e8e086ea4936",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d114ffb9-3ff0-402e-9e50-1a5db9b8fe56",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "rf = RandomForestRegressor(labelCol=\"Low\", seed=42)\n",
    "pipeline = Pipeline(stages = [stringIndexer, vecAssembler, rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c484f7-61cc-4bf9-b3bb-36a6bb244fc5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4714da6a-4130-4ad3-a58e-203ab8e88643",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "            .addGrid(rf.maxDepth, [2, 4, 6])\n",
    "            .addGrid(rf.numTrees, [10, 100])\n",
    "            .build())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c754af-888e-42ee-9c49-6e4da615615d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9b53050-8e8a-45a8-be2b-cff18d2a97bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Low\",\n",
    "                                predictionCol=\"prediction\", \n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    evaluator=evaluator, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    numFolds=3, \n",
    "                    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b404e70b-e5d0-47ec-bd43-8631030b9d34",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/13 11:52:48 WARN BlockManager: Block rdd_4426_0 already exists on this machine; not re-adding it\n"
     ]
    }
   ],
   "source": [
    "cvModel = cv.setParallelism(4).fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d71df74-ca1d-466e-bb2a-1acbd3118dc5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=rf, \n",
    "                    evaluator=evaluator, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    numFolds=3, \n",
    "                    parallelism=4, \n",
    "                    seed=42)\n",
    "\n",
    "pipeline = Pipeline(stages=[stringIndexer, vecAssembler, cv])\n",
    "\n",
    "pipelineModel = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2ebd6a0-b1d1-420c-bf2c-56e0a59f7c08",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({Param(parent='RandomForestRegressor_d1d74429f629', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 2,\n",
       "   Param(parent='RandomForestRegressor_d1d74429f629', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
       "  173.65945299918488),\n",
       " ({Param(parent='RandomForestRegressor_d1d74429f629', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 2,\n",
       "   Param(parent='RandomForestRegressor_d1d74429f629', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n",
       "  164.4144031848288),\n",
       " ({Param(parent='RandomForestRegressor_d1d74429f629', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 4,\n",
       "   Param(parent='RandomForestRegressor_d1d74429f629', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
       "  93.61794429994173),\n",
       " ({Param(parent='RandomForestRegressor_d1d74429f629', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 4,\n",
       "   Param(parent='RandomForestRegressor_d1d74429f629', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n",
       "  92.1127458998566),\n",
       " ({Param(parent='RandomForestRegressor_d1d74429f629', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 6,\n",
       "   Param(parent='RandomForestRegressor_d1d74429f629', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
       "  87.91085409951536),\n",
       " ({Param(parent='RandomForestRegressor_d1d74429f629', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 6,\n",
       "   Param(parent='RandomForestRegressor_d1d74429f629', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n",
       "  88.16646755092938)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(cvModel.getEstimatorParamMaps(), cvModel.avgMetrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6232f714-42bd-4560-ad97-f57bc13eef26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 89.15791516871782\n",
      "R2 is 0.9847921359842783\n"
     ]
    }
   ],
   "source": [
    "predDF = pipelineModel.transform(testDF)\n",
    "\n",
    "regressionEvaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"Low\", metricName=\"rmse\")\n",
    "\n",
    "rmse = regressionEvaluator.evaluate(predDF)\n",
    "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
    "print(f\"RMSE is {rmse}\")\n",
    "print(f\"R2 is {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02b70c00-336a-4dfd-96f7-bad8e1816a1a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# A littleee bit better than Decision Tree."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}